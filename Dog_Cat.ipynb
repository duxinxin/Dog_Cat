{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拆分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15547\\Anaconda3\\envs\\py3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\15547\\Anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import keras\n",
    "from dog_generator import CDGenerator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def load_data(path):\n",
    "    img_names=[]\n",
    "    img_labels=[]\n",
    "    for dpath,dnames,fnames in os.walk(path):\n",
    "#         img_names=fnames\n",
    "#         print(fnames)\n",
    "        for i in fnames:\n",
    "            img_names.append(\"train/\" + i)\n",
    "            img_labels.append(i[:3])\n",
    "#     print(img_names[-20:])\n",
    "#     print(img_labels[-20:])\n",
    "    train_x,valid_y,labels_x,labels_y = train_test_split(img_names,img_labels,test_size=0.3,random_state=42)\n",
    "\n",
    "#     cate_dict={\"cat\":0,\"dog\":1}\n",
    "#     print(labels_x[:30])\n",
    "#     print(labels_y[:30])\n",
    "#     print(len(labels_x))\n",
    "    train_labels=[]\n",
    "    valid_labels=[]\n",
    "    for i in labels_x:\n",
    "        if i == 'cat':\n",
    "            train_labels.append(0)\n",
    "        else:\n",
    "            train_labels.append(1)\n",
    "       \n",
    "    for j in labels_y:\n",
    "        if j == 'cat':\n",
    "            valid_labels.append(0)\n",
    "        else:\n",
    "            valid_labels.append(1)\n",
    "#     print(len(train_labels),len(valid_labels))\n",
    "#     print(valid_labels[:30])\n",
    "\n",
    "    return train_x,valid_y,train_labels,valid_labels\n",
    "# load_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载测试集图片\n",
    "import cv2\n",
    "def load_test():\n",
    "    imgs = []\n",
    "    for i in os.listdir('test'):\n",
    "#         img = cv2.imread('test/'+i)\n",
    "#         img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "#         img = cv2.resize(img,des_size)\n",
    "#         imgs.append(img)\n",
    "        \n",
    "        imgs.append('test/'+i)\n",
    "#     print(len(imgs))\n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img,valid_img,train_labels,valid_labels=load_data(\"train\")\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "# print(len(train_labels))\n",
    "train_generator = CDGenerator((train_img,train_labels),\n",
    "                                len(train_img),'train',is_directory=True,batch_size=batch_size,seed=0)\n",
    "\n",
    "valid_generator = CDGenerator((valid_img,valid_labels),\n",
    "                                len(valid_img),'valid',is_directory=True,batch_size=batch_size,seed=0)\n",
    "\n",
    "test_imgs = load_test()\n",
    "test_generator = CDGenerator((test_imgs,None),\n",
    "                                len(test_imgs),'test',is_directory=True,batch_size=batch_size,seed=0)\n",
    "# print(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img,valid_img,train_labels,valid_labels=load_data(\"train\")\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "train_generator = CDGenerator((train_img,train_labels),\n",
    "                                len(train_img),'train',des_size=(299,299),\n",
    "                                is_directory=True,batch_size=batch_size,seed=0)\n",
    "\n",
    "valid_generator = CDGenerator((valid_img,valid_labels),\n",
    "                                len(valid_img),'valid',des_size=(299,299),\n",
    "                                is_directory=True,batch_size=batch_size,seed=0)\n",
    "\n",
    "test_imgs = load_test()\n",
    "test_generator = CDGenerator((test_imgs,None),len(test_imgs),'test',\n",
    "                             des_size=(299,299),is_directory=True,\n",
    "                             batch_size=batch_size,seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg19,resnet50,inception_v3,xception\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,Convolution2D,MaxPooling2D,Dense,Activation,Dropout,Flatten\n",
    "import h5py\n",
    "from keras.applications.resnet50 import preprocess_input as res_preprocess_input\n",
    "from keras.applications.xception import preprocess_input as xcep_preprocess_input\n",
    "from keras.applications.inception_v3 import preprocess_input as incep_preprocess_input\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "546/546 [==============================] - 220s 402ms/step - loss: 0.1426 - acc: 0.9405 - val_loss: 0.0618 - val_acc: 0.9736\n",
      "Epoch 2/5\n",
      "546/546 [==============================] - 216s 395ms/step - loss: 0.0821 - acc: 0.9697 - val_loss: 0.0470 - val_acc: 0.9814\n",
      "Epoch 3/5\n",
      "546/546 [==============================] - 215s 395ms/step - loss: 0.0748 - acc: 0.9714 - val_loss: 0.0645 - val_acc: 0.9752\n",
      "Epoch 4/5\n",
      "546/546 [==============================] - 214s 392ms/step - loss: 0.0778 - acc: 0.9712 - val_loss: 0.0499 - val_acc: 0.9819\n",
      "Epoch 5/5\n",
      "546/546 [==============================] - 212s 388ms/step - loss: 0.0722 - acc: 0.9720 - val_loss: 0.0381 - val_acc: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdda93635f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = keras.layers.Input(shape=(224,224,3))\n",
    "process_input = keras.layers.Lambda(res_preprocess_input)(Input)\n",
    "resnet = resnet50.ResNet50(include_top=False,weights=\"imagenet\",input_tensor=process_input,pooling=\"avg\")\n",
    "resModel = Model(inputs=resnet.input,outputs=resnet.output)\n",
    "output = resModel.output\n",
    "output=Dropout(0.5)(output)\n",
    "predictions = Dense(1,activation=\"sigmoid\")(output)\n",
    "model = Model(inputs=resModel.input, outputs=predictions)\n",
    "\n",
    "for layers in resnet.layers:\n",
    "    layers.trainable=False\n",
    "    \n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,len(train_img)//batch_size,\n",
    "                    epochs=epochs,verbose=1,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=len(valid_img)// batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('resnet_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img,valid_img,train_labels,valid_labels=load_data(\"train\")\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "# print(len(train_labels))\n",
    "train_generator = CDGenerator((train_img,train_labels),\n",
    "                                len(train_img),des_size=(299,299),\n",
    "                                is_directory=True,batch_size=batch_size,seed=0)\n",
    "\n",
    "valid_generator = CDGenerator((valid_img,valid_labels),\n",
    "                                len(valid_img),des_size=(299,299),\n",
    "                                is_directory=True,batch_size=batch_size,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "546/546 [==============================] - 295s 540ms/step - loss: 0.1866 - acc: 0.9315 - val_loss: 0.0666 - val_acc: 0.9812\n",
      "Epoch 2/5\n",
      "546/546 [==============================] - 284s 521ms/step - loss: 0.1103 - acc: 0.9592 - val_loss: 0.0428 - val_acc: 0.9884\n",
      "Epoch 3/5\n",
      "546/546 [==============================] - 283s 519ms/step - loss: 0.0973 - acc: 0.9639 - val_loss: 0.0545 - val_acc: 0.9850\n",
      "Epoch 4/5\n",
      "546/546 [==============================] - 284s 520ms/step - loss: 0.0968 - acc: 0.9656 - val_loss: 0.0656 - val_acc: 0.9807\n",
      "Epoch 5/5\n",
      "546/546 [==============================] - 284s 520ms/step - loss: 0.0924 - acc: 0.9651 - val_loss: 0.0707 - val_acc: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4b6f376d30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = keras.layers.Input(shape=(299,299,3))\n",
    "process_input = keras.layers.Lambda(incep_preprocess_input)(Input)\n",
    "ince_v3 = inception_v3.InceptionV3(include_top=False,weights=\"imagenet\",input_tensor=process_input,pooling=\"avg\")\n",
    "inceModel = Model(inputs=ince_v3.input,outputs=ince_v3.output)\n",
    "output = inceModel.output\n",
    "output=Dropout(0.5)(output)\n",
    "predictions = Dense(1,activation=\"sigmoid\")(output)\n",
    "model = Model(inputs=inceModel.input, outputs=predictions)\n",
    "\n",
    "for layers in ince_v3.layers:\n",
    "    layers.trainable=False\n",
    "    \n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,len(train_img)//batch_size,\n",
    "                    epochs=epochs,verbose=1,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=len(valid_img)// batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('ince_v3_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img,valid_img,train_labels,valid_labels=load_data(\"train\")\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "# print(len(train_labels))\n",
    "train_generator = CDGenerator((train_img,train_labels),\n",
    "                                len(train_img),des_size=(299,299),\n",
    "                                is_directory=True,batch_size=batch_size,seed=0)\n",
    "\n",
    "valid_generator = CDGenerator((valid_img,valid_labels),\n",
    "                                len(valid_img),des_size=(299,299),\n",
    "                                is_directory=True,batch_size=batch_size,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "546/546 [==============================] - 515s 943ms/step - loss: 0.1148 - acc: 0.9720 - val_loss: 0.0893 - val_acc: 0.9782\n",
      "Epoch 2/5\n",
      "546/546 [==============================] - 512s 937ms/step - loss: 0.0547 - acc: 0.9821 - val_loss: 0.0563 - val_acc: 0.9863\n",
      "Epoch 3/5\n",
      "546/546 [==============================] - 511s 937ms/step - loss: 0.0465 - acc: 0.9848 - val_loss: 0.0726 - val_acc: 0.9804\n",
      "Epoch 4/5\n",
      "546/546 [==============================] - 512s 937ms/step - loss: 0.0417 - acc: 0.9861 - val_loss: 0.0699 - val_acc: 0.9813\n",
      "Epoch 5/5\n",
      "546/546 [==============================] - 512s 937ms/step - loss: 0.0388 - acc: 0.9860 - val_loss: 0.0713 - val_acc: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4b382a5470>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = keras.layers.Input(shape=(299,299,3))\n",
    "process_input = keras.layers.Lambda(xcep_preprocess_input)(Input)\n",
    "xception = xception.Xception(include_top=False,weights=\"imagenet\",input_tensor=process_input,pooling=\"avg\")\n",
    "xceModel = Model(inputs=xception.input,outputs=xception.output)\n",
    "output = xceModel.output\n",
    "output=Dropout(0.25)(output)\n",
    "predictions = Dense(1,activation=\"sigmoid\")(output)\n",
    "model = Model(inputs=xceModel.input, outputs=predictions)\n",
    "\n",
    "for layers in xception.layers:\n",
    "    layers.trainable=False\n",
    "    \n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_generator,len(train_img)//batch_size,\n",
    "                    epochs=epochs,verbose=1,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=len(valid_img)// batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('xception_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input = keras.layers.Input(shape=(299,299,3))\n",
    "process_input = keras.layers.Lambda(xcep_preprocess_input)(Input)\n",
    "xception = xception.Xception(include_top=False,weights=\"imagenet\",input_tensor=process_input,pooling=\"avg\")\n",
    "xceModel = Model(inputs=xception.input,outputs=xception.output)\n",
    "output = xceModel.output\n",
    "output=Dropout(0.25)(output)\n",
    "predictions = Dense(1,activation=\"sigmoid\")(output)\n",
    "model = Model(inputs=xceModel.input, outputs=predictions)\n",
    "\n",
    "for layers in xception.layers:\n",
    "    layers.trainable=False\n",
    "    \n",
    "model.load_weights('xception_weights.h5')\n",
    "\n",
    "test_imgs = load_test((299,299))\n",
    "# print(process_input.shape)\n",
    "# print(test_imgs[0].shape)\n",
    "image = test_imgs[0]\n",
    "new_img = np.expand_dims(image,axis=0)\n",
    "print(new_img.shape)\n",
    "result = model.predict(new_img)\n",
    "print(result)\n",
    "print(decode_predictions(result,top=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征向量的导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def output_features(model_name,model,train_generator,train_labels,valid_generator,valid_labels,test_generator,batch_size=32):\n",
    "    if model_name == 'resnet_features':\n",
    "        model.load_weights('resnet_weights.h5',by_name=True)\n",
    "    elif model_name == 'ince_v3_features':\n",
    "        model.load_weights('ince_v3_weights.h5',by_name=True)\n",
    "    else:\n",
    "        model.load_weights('xception_weights.h5',by_name=True)\n",
    "    \n",
    "    #将labels转成array\n",
    "    train_labels = np.array(train_labels)\n",
    "    valid_labels = np.array(valid_labels)\n",
    "    \n",
    "    #trian、valid、test的features\n",
    "    train_features = model.predict_generator(train_generator,int(np.ceil(train_generator.n/batch_size)),verbose=1)\n",
    "    valid_features = model.predict_generator(valid_generator,int(np.ceil(valid_generator.n/batch_size)),verbose=1)\n",
    "    test_features = model.predict_generator(test_generator,int(np.ceil(test_generator.n/batch_size)),verbose=1)\n",
    "    \n",
    "    with h5py.File(model_name+'.h5','w') as file:\n",
    "        file.create_dataset('train',data=train_features,dtype='float32')\n",
    "        file.create_dataset('train_labels',data=np.array(train_generator.y),dtype='uint8')\n",
    "        file.create_dataset('valid',data=valid_features,dtype='float32')\n",
    "        file.create_dataset('valid_labels',data=np.array(valid_generator.y),dtype='uint8')\n",
    "        file.create_dataset('test',data=test_features,dtype='float32')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"global_average_pooling2d_2/Mean:0\", shape=(?, 2048), dtype=float32)\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(uid, i)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \"\"\"\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\dog_cat\\dog_generator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     41\u001b[0m \t\t\t\t\t\t\t\t\t\tself.batch_size*(idx+1)]\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\dog_cat\\dog_generator.py\u001b[0m in \u001b[0;36m_data_generate\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_data_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdes_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdes_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8747f1ab91b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres50\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m output_features('resnet_features',Model(inputs=res50.input,outputs=res50.output),\n\u001b[1;32m----> 5\u001b[1;33m                 train_generator,train_labels,valid_generator,valid_labels,test_generator)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-7456d453af22>\u001b[0m in \u001b[0;36moutput_features\u001b[1;34m(model_name, model, train_generator, train_labels, valid_generator, valid_labels, test_generator, batch_size)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#trian、valid、test的features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtrain_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mvalid_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   2520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2522\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2523\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2524\u001b[0m                     \u001b[1;31m# Compatibility with the generators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "#resnet\n",
    "res50 = resnet50.ResNet50(include_top=False,weights=\"imagenet\",input_shape=(224,224,3),pooling=\"avg\")\n",
    "print(res50.output)\n",
    "output_features('resnet_features',Model(inputs=res50.input,outputs=res50.output),\n",
    "                train_generator,train_labels,valid_generator,valid_labels,test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"global_average_pooling2d_3/Mean:0\", shape=(?, 2048), dtype=float32)\n",
      "547/547 [==============================] - 241s 441ms/step\n",
      "235/235 [==============================] - 102s 434ms/step\n",
      "391/391 [==============================] - 169s 433ms/step\n"
     ]
    }
   ],
   "source": [
    "#inception\n",
    "Input = keras.layers.Input(shape=(299,299,3))\n",
    "process_input = keras.layers.Lambda(incep_preprocess_input)(Input)\n",
    "ince_v3 = inception_v3.InceptionV3(include_top=False,weights=\"imagenet\",input_tensor=process_input,pooling=\"avg\")\n",
    "print(ince_v3.output)\n",
    "output_features('ince_v3_features',Model(inputs=ince_v3.input,outputs=ince_v3.output),\n",
    "                train_generator,train_labels,valid_generator,valid_labels,test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"global_average_pooling2d_8/Mean:0\", shape=(?, 2048), dtype=float32)\n",
      "547/547 [==============================] - 438s 801ms/step\n",
      "235/235 [==============================] - 186s 793ms/step\n",
      "391/391 [==============================] - 310s 793ms/step\n"
     ]
    }
   ],
   "source": [
    "#xception\n",
    "Input = keras.layers.Input(shape=(299,299,3))\n",
    "process_input = keras.layers.Lambda(xcep_preprocess_input)(Input)\n",
    "xception = xception.Xception(include_top=False,weights=\"imagenet\",input_tensor=process_input,pooling=\"avg\")\n",
    "print(xception.output)\n",
    "output_features('xception_features',Model(inputs=xception.input,outputs=xception.output),\n",
    "                train_generator,train_labels,valid_generator,valid_labels,test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型的融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 2048) (7500, 2048) (12500, 2048)\n",
      "(17500, 2048) (7500, 2048) (12500, 2048)\n",
      "(17500, 2048) (7500, 2048) (12500, 2048)\n",
      "(17500, 6144) (7500, 6144) (12500, 6144)\n"
     ]
    }
   ],
   "source": [
    "feature_files = ['resnet_features.h5','ince_v3_features.h5','xception_features.h5']\n",
    "\n",
    "X_train =[]\n",
    "y_train =[]\n",
    "X_valid =[]\n",
    "y_valid =[]\n",
    "X_test =[]\n",
    "\n",
    "for file_name in feature_files:\n",
    "    with h5py.File(file_name,'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        y_train = (np.array(h['train_labels']))\n",
    "        \n",
    "        X_test.append(np.array(h['test']))\n",
    "        \n",
    "        X_valid.append(np.array(h['valid']))\n",
    "        y_valid = (np.array(h['valid_labels']))\n",
    "        print(np.array(h['train']).shape,np.array(h['valid']).shape,np.array(h['test']).shape)\n",
    "#         print(X_train[:3],y_train[:3])\n",
    "train = np.concatenate(X_train,axis=1)\n",
    "valid = np.concatenate(X_valid,axis=1)\n",
    "test  = np.concatenate(X_test, axis=1)\n",
    "print(train.shape,valid.shape,test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# print(np.array(y_train).shape)\n",
    "X_train,y_train = shuffle(train,y_train)\n",
    "# print(len(X_train),len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_2:0\", shape=(?, 6144), dtype=float32)\n",
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/5\n",
      "17500/17500 [==============================] - 1s 80us/step - loss: 0.7712 - acc: 0.4906 - val_loss: 0.7136 - val_acc: 0.5021\n",
      "Epoch 2/5\n",
      "17500/17500 [==============================] - 1s 71us/step - loss: 0.7345 - acc: 0.5211 - val_loss: 0.7056 - val_acc: 0.5073\n",
      "Epoch 3/5\n",
      "17500/17500 [==============================] - 1s 74us/step - loss: 0.7254 - acc: 0.5252 - val_loss: 0.7093 - val_acc: 0.5023\n",
      "Epoch 4/5\n",
      "17500/17500 [==============================] - 1s 76us/step - loss: 0.7129 - acc: 0.5392 - val_loss: 0.7167 - val_acc: 0.5012\n",
      "Epoch 5/5\n",
      "17500/17500 [==============================] - 1s 74us/step - loss: 0.7108 - acc: 0.5448 - val_loss: 0.7098 - val_acc: 0.5081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28eaad0b390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.utils\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "print(input_tensor)\n",
    "# print(X_train)\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "output = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "con_model = Model(inputs=input_tensor,outputs=output)\n",
    "con_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "con_model.fit(X_train,y_train,batch_size=128, epochs=5,validation_data=(valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
